{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFLite Optimizations and Quantization\n",
    "\n",
    "> In this post, we will explore optimization impact on size, performance and accuracy. This is the summary of lecture \"Applications of TinyML\" from edX.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Chanseok Kang\n",
    "- categories: [Python, edX, Deep_Learning, Tensorflow, tinyML]\n",
    "- image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow : v2.3.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"Tensorflow : v\" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23262\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 224, 224, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format images to have normalized pixels\n",
    "def format_image(image, label):\n",
    "    image = tf.image.resize(image, (224, 224)) / 255.0\n",
    "    return  image, label\n",
    "\n",
    "# load in our dataset\n",
    "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "\n",
    "# display how much data we have\n",
    "num_examples = metadata.splits['train'].num_examples\n",
    "num_classes = metadata.features['label'].num_classes\n",
    "print(num_examples)\n",
    "print(num_classes)\n",
    "\n",
    "# split the data in training, validation, and test datasets\n",
    "BATCH_SIZE = 32\n",
    "train_batches = raw_train.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "validation_batches = raw_validation.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "test_batches = raw_test.map(format_image).batch(1)\n",
    "\n",
    "# display the shape of our data\n",
    "for image_batch, label_batch in train_batches.take(1):\n",
    "    pass\n",
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4 with input size (224, 224) and output dimension 1280\n",
      "Building model with https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "module_selection = (\"mobilenet_v2\", 224, 1280) \n",
    "handle_base, pixels, FV_SIZE = module_selection\n",
    "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "print(\"Using {} with input size {} and output dimension {}\".format(MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))\n",
    "\n",
    "feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
    "                                   input_shape=IMAGE_SIZE + (3,), \n",
    "                                   output_shape=[FV_SIZE],\n",
    "                                   trainable=False)\n",
    "\n",
    "print(\"Building model with\", MODULE_HANDLE)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        feature_extractor,\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Save model\n",
    "\n",
    "Since we are doing transfer learning to fine tune a pre-trained model to our dataset we only need to use 5 Epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "582/582 [==============================] - 18s 31ms/step - loss: 0.0520 - accuracy: 0.9822 - val_loss: 0.0369 - val_accuracy: 0.9858\n",
      "Epoch 2/5\n",
      "582/582 [==============================] - 11s 19ms/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 0.0394 - val_accuracy: 0.9862\n",
      "Epoch 3/5\n",
      "582/582 [==============================] - 12s 20ms/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 0.0372 - val_accuracy: 0.9884\n",
      "Epoch 4/5\n",
      "582/582 [==============================] - 11s 19ms/step - loss: 0.0209 - accuracy: 0.9927 - val_loss: 0.0377 - val_accuracy: 0.9880\n",
      "Epoch 5/5\n",
      "582/582 [==============================] - 11s 20ms/step - loss: 0.0188 - accuracy: 0.9936 - val_loss: 0.0407 - val_accuracy: 0.9871\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "hist = model.fit(train_batches,\n",
    "                 epochs=EPOCHS,\n",
    "                 validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kcsgo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kcsgo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kcsgo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kcsgo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp_saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp_saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "CATS_VS_DOGS_SAVED_MODEL = \"exp_saved_model\"\n",
    "tf.saved_model.save(model, CATS_VS_DOGS_SAVED_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model optimization & Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(CATS_VS_DOGS_SAVED_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Optimization & Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8944916"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model = converter.convert()\n",
    "tflite_models_dir = pathlib.Path(\"./\")\n",
    "\n",
    "tflite_model_file = tflite_models_dir/'model_noop.tflite'\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2389808"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "tflite_models_dir = pathlib.Path(\"./\")\n",
    "\n",
    "tflite_model_file = tflite_models_dir/'model_op_default.tflite'\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Optimization and quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2923024"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value, _ in test_batches.take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "tflite_models_dir = pathlib.Path(\"./\")\n",
    "\n",
    "tflite_model_file = tflite_models_dir/'model_op_default_quant.tflite'\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['cat', 'dog']\n",
    "\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    img = np.squeeze(img)\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "    \n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    \n",
    "    if predicted_label == true_label:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                         100*np.max(predictions_array),\n",
    "                                         class_names[true_label]), color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 27.20it/s]\n",
      "  1%|▊                                                                                 | 1/100 [00:00<00:18,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 100 predictions I got 99 correct on model_noop.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:10<00:00,  9.30it/s]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 100 predictions I got 93 correct on model_op_default.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:12<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 100 predictions I got 99 correct on model_op_default_quant.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for tflite_model_file in ['model_noop.tflite', 'model_op_default.tflite', 'model_op_default_quant.tflite']:\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    test_labels, test_imgs = [], []\n",
    "    for img, label in tqdm(test_batches.take(100)):\n",
    "        interpreter.set_tensor(input_index, img)\n",
    "        interpreter.invoke()\n",
    "        predictions.append(interpreter.get_tensor(output_index))\n",
    "\n",
    "        test_labels.append(label.numpy()[0])\n",
    "        test_imgs.append(img)\n",
    "        \n",
    "    score = 0\n",
    "    for item in range(0,99):\n",
    "        prediction=np.argmax(predictions[item])\n",
    "        label = test_labels[item]\n",
    "        if prediction==label:\n",
    "            score +=1\n",
    "\n",
    "    print(\"Out of 100 predictions I got \" + str(score) + \" correct on \" + tflite_model_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
